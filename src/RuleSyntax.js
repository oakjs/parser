import flatten from "lodash/flatten.js";

import Parser from "./Parser.js";
import ParseError from "./ParseError.js";
import Rule from "./Rule.js";
import Tokenizer from "./Tokenizer.js";
import { cloneClass } from "./utils/class.js";

//
//  # Parsing `ruleSyntax` to create rules automatically.
//
// TODO:  Better name for `ruleSyntax`
// TODO:  Use keywords in syntax to make a quick regex-based `test` function for the entire rule

//
// ## group: parsing syntax
//

// Return array of rules generated by parsing rule `syntax`, instantiating with `constructor` passed in.
export default function parseRule(syntax, constructor) {
  // If we got an array of possible syntaxes...
  if (Array.isArray(syntax)) {
    // ...recursively parse each syntax, using a CLONE of the constructor.
    return flatten(syntax.map(syntax => parseRule(syntax, constructor)));
  }

  let rules = parseSyntax(syntax);
  if (rules.length === 0) {
    throw new ParseError(`parser.defineRule(${syntax}): no rule produced`);
  }

  // If no constructor, just return the rule(s) from parseSyntax()
  if (!constructor) {
    // If we only got one rule, just return it
    if (rules.length === 1) return rules;

    // Otherwise return a sequence with the specified rules
    return [new Rule.Sequence({ rules })];
  }

  // Make an instance of the provided constructor
  const rule = new constructor();

  // If the rule is a sequence, copy `rules` to it
  if (rule instanceof Rule.Sequence) {
    Object.defineProperty(rule, "rules", { value: rules });
  }
  // otherwise add properties from first matched rule to the instance
  else {
    if (rules.length > 1) throw new ParseError("parseRule(): expected a single rule back");
    // Copy non-enumerably so we'll throw if someone tries to override them.
    for (const property in rules[0]) {
      Object.defineProperty(rule, property, { value: rules[0][property] });
    }
  }

  return [rule];
}

export function tokeniseRuleSyntax(syntax) {
  const SYNTAX_EXPRESSION = /(?:[\w\-]+|[\\\[\(\{\)\}\]]|[^\s\w]|\|)/g;
  let syntaxStream = syntax.match(SYNTAX_EXPRESSION);
//TESTME
  if (!syntaxStream) throw new ParseError(`Can't tokenize parse rule syntax >>${syntax}<<`);
  return syntaxStream;
}

export function parseSyntax(syntax, rules = [], start = 0) {
  //TESTME
  if (syntax == null) throw new ParseError("parseSyntax(): `syntax` is required");
  const syntaxStream = typeof syntax === "string" ? tokeniseRuleSyntax(syntax) : syntax;

  let lastIndex = syntaxStream.length;
  while (start < lastIndex) {
    let [rule, end] = parseToken(syntaxStream, rules, start);
    if (rule) {
      rules.push(rule);
    }
    start = end + 1;
  }
  return rules;
}

const KEYWORD_PATTERN = /[A-Za-z][\w_-]*/;
function parseToken(syntaxStream, rules = [], start = 0) {
  let token = syntaxStream[start];
  switch (token) {
    case "{":
      return parseSubrule(syntaxStream, rules, start);
    case "(":
      return parseGroup(syntaxStream, rules, start);
    case "[":
      return parseList(syntaxStream, rules, start);
    case "*":
    case "+":
    case "?":
      return parseRepeat(syntaxStream, rules, start);

    // the following should ALWAYS be consumed by the above
    case "}":
    case ")":
    case "]":
    case "|":
      throw new ParseError(`Unexpected ${token} found as item ${start} of \`${syntaxStream.join("")}\``);

    default:
      if (token.match(KEYWORD_PATTERN)) {
        return parseKeyword(syntaxStream, rules, start);
      } else {
        return parseSymbol(syntaxStream, rules, start);
      }
  }
}

// Match `keyword`s in syntax rules.
// If more than one keyword appears in a row, combines them into a single `Keyword` object.
// This is pretty safe, unless you have an optional keyword like
//    `the {identifier} of the? {expression}`
// in which case you can put the optional keyword in parens
//    `the {identifier} of (the?) {expression}`
//
// Returns `[ rule, end ]`
function parseKeyword(syntaxStream, rules, start = 0, constructor = Rule.Keywords) {
  let literals = [];
  let end;
  // eat keywords while they last
  for (var i = start; i < syntaxStream.length; i++) {
    let keyword = syntaxStream[i];
    if (!keyword.match(KEYWORD_PATTERN)) break;

    if (literals.length > 0 && syntaxStream[i+1] === "?") break;
    literals.push(keyword);
    end = i;
  }

  let rule = new constructor({ literals });
  return [rule, end];
}

const ESCAPED_SYMBOLS = ["{", "(", "[", "|", "*", "+", "?", "]", ")", "}"];

// Match one or more `symbol`s in syntax rules.
// Returns `[ rule, end ]`
function parseSymbol(syntaxStream, rules, start = 0, constructor = Rule.Symbols) {
  const literals = [];
  const echo = [];
  let end;
  // eat keywords while they last
  for (var i = start; i < syntaxStream.length; i++) {
    let symbol = syntaxStream[i];

    // eat "\\" as escape character, work with next item in stream
    const escaped = symbol === "\\";
    if (escaped) symbol = syntaxStream[++i];

    // forget it if we got a keyword
    if (!symbol || symbol.match(KEYWORD_PATTERN)) break;
    // forget it if not escaped and it's one of our special characters
    if (!escaped && ESCAPED_SYMBOLS.includes(symbol)) break;
    // Don't mush together if next rule is optional
    if (literals.length > 0 && syntaxStream[i+1] === "?") break;

    literals.push(symbol);
    echo.push(escaped ? `\\${symbol}` : symbol);
    end = i;
  }

  const rule = new constructor({
    literals,
    toSyntax() {
      return `${echo.join("")}${this.optional ? "?" : ""}`;
    }
  });
  return [rule, end];
}

// Match grouping expression `(...|...)` in syntax rules.
// Returns `[ rule, end ]`
// You can specify an explicit `rule.argument` with:  `(somearg:...)`
// You can specify that the results should be `promoted` to enclosing rule with: `(?:...)`
//
// NOTE: nested parens may not have alternatives... :-(   `(a|(b|c))` won't work???
function parseGroup(syntaxStream, rules, start = 0) {
  let { end, slice } = Tokenizer.findNestedTokens(syntaxStream, "(", ")", start);

  // pull out explicit "promote" flag: `?:`
  let promote = slice[0] === "?" && slice[1] === ":";
  if (promote) {
    slice = slice.slice(2);
  }

  // pull out explicit argument name
  let argument;
  if (slice.length > 2 && slice[1] === ":") {
    argument = slice[0];
    slice = slice.slice(2);
  }

  // split into groups, including nested parens
  let alternatives = groupAlternatives(slice).map(function(group) {
    let results = parseSyntax(group, []);
    if (results.length === 1) {
      return results[0];
    } else {
      return new Rule.Sequence({ rules: results });
    }
  });

  let rule =
    alternatives.length === 1 ? alternatives[0] : new Rule.Alternatives({ rules: alternatives });

  if (argument) rule.argument = argument;
  if (promote) rule.promote = true;
  return [rule, end];
}

function groupAlternatives(tokens) {
  let alternatives = [];
  let current = [];
  for (let i = 0, token; (token = tokens[i]); i++) {
    // handle alternate marker
    if (token === "|") {
      alternatives.push(current);
      current = [];
    }
    // handle nested parens
    else if (token === "(") {
      let { end } = Tokenizer.findNestedTokens(tokens, "(", ")", i);
      current = current.concat(tokens.slice(i, end + 1));
      i = end;
    } else {
      current.push(token);
    }
  }
  if (current.length) alternatives.push(current);
  return alternatives;
}

// Match repeat indicator `?`, `+` or `*` by attaching it to the previous rule.
function parseRepeat(syntaxStream, rules, start = 0) {
  let symbol = syntaxStream[start];
  let rule = rules[rules.length - 1];
  //TESTME
  if (!rule) throw new ParseError(`Can't attach repeat symbol ${symbol} to empty rule!`);

  // Transform last rule into a repeat for `*` and `+`.
  if (symbol === "*" || symbol === "+") {
    let argument = rule.argument;
    rule = new Rule.Repeat({ repeat: rule });
    if (argument) rule.argument = argument;
    // push into rule stack in place of old rule
    rules[rules.length - 1] = rule;
  }

  // Rule is optional for `?` and `*`.
  if (symbol === "?" || symbol === "*") {
    rule.optional = true;
  }

  return [undefined, start];
}

// Match `{<subrule>}` in syntax rules.
// Returns `[ rule, end ]`
// Throws if invalid.
function parseSubrule(syntaxStream, rules, start = 0) {
  const match = Tokenizer.findNestedTokens(syntaxStream, "{", "}", start);
  const props = {};
  // handle promote flag: "?:"
  if (match.slice[0] === "?" && match.slice[1] === ":") {
    props.promote = true;
    match.slice = match.slice.slice(2);
  }

  // handle argument
  if (match.slice[1] === ":") {
    props.argument = match.slice[0];
    match.slice = match.slice.slice(2);
  }

  if (match.slice.length !== 1)
    throw new ParseError(
      `Can't process subrules with more than one rule name: {${match.slice.join("")}}`
    );

  props.subrule = match.slice[0];

  // see if there's a `not` rule in there
//   const bangPosition = props.subrule.indexOf("!");
//   if (bangPosition !== -1) {
//     props.not = props.subrule.substr(bangPosition + 1);
//     props.subrule = props.subrule.substr(0, bangPosition);
//   }

  const rule = new Rule.Subrule(props);
  return [rule, match.end];
}

// Match list expression `[<item><delimiter>]` or `[<argument>:<item><delimiter>]` in syntax rules.
// Returns `[ rule, end ]`
// Throws if invalid.
function parseList(syntaxStream, rules, start = 0, constructor = Rule.List) {
  let { end, slice } = Tokenizer.findNestedTokens(syntaxStream, "[", "]", start);

  // get argument if supplied
  let argument;
  if (slice.length > 2 && slice[1] === ":") {
    argument = slice[0];
    slice = slice.slice(2);
  }

  let results = parseSyntax(slice, []);
  if (results.length !== 2) {
    throw new ParseError(`Unexpected stuff at end of list: [${slice.join(" ")}]`);
  }
  let [item, delimiter] = results;

  let rule = new constructor({ item, delimiter });
  if (argument) rule.argument = argument;
  return [rule, end];
}
